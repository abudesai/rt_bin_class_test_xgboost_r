#!/usr/bin/env Rscript

## ---- Initialising libraries ----
print('Initializing libraries')
library(ggplot2)
library(tibble)
library(tidyr)
library(readr)
library(purrr)
library(dplyr)
library(stringr)
library(lubridate)
library(plotly)
library(glue)
library(zeallot)
library(xgboost)
library(pROC)
library(forcats)
library(rjson)
library(caTools)
library(imputeTS)

options(dplyr.summarise.inform = FALSE)


## Script that holp helper functions
source('algorithm/0.common_funcs.R')


## get the json file for the schema
print("get schema data...")
schema <-
  glue('/opt/ml_vol/inputs/data_config/',
       list.files(path = "/opt/ml_vol/inputs/data_config"))

## Get the training data file
print("get training data...")
data   <-
  glue(
    '/opt/ml_vol/inputs/data/training/binaryClassificationBaseMainInput/',
    list.files(path = "/opt/ml_vol/inputs/data/training/binaryClassificationBaseMainInput")
  )

## Get the hyperparameters file
# hpt   <-
#   glue(
#     '/opt/ml_vol/model/model_config/',
#     list.files(path = "/opt/ml_vol/model/model_config/")
#   )

trainer <- function(schema_path, data_path)
{
  
  
  ## Reading model hyperparameters
  # hpt <- fromJSON(file = hpt_path)
  
  eta_p       = 0.3
  max_depth_p = 5
  nrounds_p   = 1000

  
  
  hypergrid <- expand_grid(
    eta       = eta_p,
    max_depth = max_depth_p,
    nrounds   = nrounds_p,
    auc       = 0
  )

  ## Reading schema
  print("Reading schema..")
  file <- fromJSON(file = schema_path)
  
  ## Saving id, target, and target class in variables
  id_column    <-
    file$inputDatasets$binaryClassificationBaseMainInput$idField
  target_column       <-
    file$inputDatasets$binaryClassificationBaseMainInput$targetField
  target_class <-
    file$inputDatasets$binaryClassificationBaseMainInput$targetClass
  features = file$inputDatasets$binaryClassificationBaseMainInput$predictorFields
  
  
  ## Splitting data into two categories (Numerical and Categorical)
  print("Splitting data into two categories (Numerical and Categorical)..")
  exp_vars            <- c()
  variables_to_encode <- c()
  variables_numeric     <- c()
  for (field in features)
  {
    type <- field[['dataType']]
    name <- field[['fieldName']]
    
    if (type == 'CATEGORICAL')
    {
      variables_to_encode <- c(variables_to_encode, name)
      exp_vars           <- c(exp_vars, name)
    } else
    {
      exp_vars           <- c(exp_vars, name)
      variables_numeric    <- c(variables_numeric, name)
    }
  }
  
  
  ## Reading training data and dropping any row with no label
  print("Reading training data..")  
  full_data <-
    read_csv(data_path) %>% drop_na(target_column)
  
  ## Changing datatype of categorical and numeric variables as received from json file
  print("Changing datatype of categorical and numeric variables..")
  full_data[variables_to_encode] <-
    sapply(full_data[variables_to_encode], as.character)
  full_data[variables_numeric]   <-
    sapply(full_data[variables_numeric], as.numeric)
  
  id     <- full_data[, id_column]
  target <- full_data[, target_column]
  
  ## Impute missing values
  ## With mean for numeric fields
  ## And mode for categorical fields
  print("Impute missing values..")
  full_data_numeric <-
    full_data %>% select(variables_numeric) %>% na_mean(option = "mean")
  full_data_categorical <-
    full_data  %>% select(variables_to_encode) %>%
    mutate(across(everything(), ~ replace_na(.x, calc_mode(.x))))
  
  
  full_data <-
    cbind(id, full_data_numeric, full_data_categorical, target)
  
  ## Splitting data to train and validation. 70% and 30%
  print("Splitting data to train and validation..")
  set.seed(6789)
  split = sample.split(full_data[[target_column]], SplitRatio = 0.7)
  df_train_split = subset(full_data, split == TRUE)
  df_val_split = subset(full_data, split == FALSE)
  
  
  ## Encoding categorical variables
  print("feature encoding..")
  categories <- full_data[target_column] %>% distinct()
  categories <- categories[[1]]
  other_class <- categories[!(categories %in% target_class)]
  
  colnames(df_train_split)[colnames(df_train_split)==get('target_column')] = "label"
  colnames(df_val_split)[colnames(df_val_split)==get('target_column')] = "label"
  
  df_train <-
    df_train_split %>% mutate(y = label)
  
  df_val   <-
    df_val_split %>% mutate(y = label) 
  
  df_train["y"][df_train["y"] == get("target_class")] <- TRUE
  df_train["y"][df_train["y"] == get("other_class")] <- FALSE
  df_val["y"][df_val["y"] == get("target_class")] <- TRUE
  df_val["y"][df_val["y"] == get("other_class")] <- FALSE
  
  df_train$y <- df_train$y %>% as.logical()
  df_val$y <- df_val$y %>% as.logical()
  
  
  if(length(variables_to_encode) != 0)
  {
    c(df_train, df_val, dummy, encodings) %<-% target_encode_these(df_train, df_val, variables_to_encode)
    df_train <-
      df_train %>% select(-y) %>% filter_if(is.numeric, ~ !is.infinite(.))
    df_val   <-
      df_val   %>% select(-y) %>% filter_if(is.numeric, ~ !is.infinite(.))
    colnames(df_train) <-
      colnames(df_train) %>% str_replace('_target_encoded$', '')
    colnames(df_val) <-
      colnames(df_val) %>% str_replace('_target_encoded$', '')
  } else{
    encodings <- NULL
  }
  
  
  df_train["label"][df_train["label"] == get("target_class")] <- 1
  df_train["label"][df_train["label"] == get("other_class")] <- 0
  df_val["label"][df_val["label"] == get("target_class")] <- 1
  df_val["label"][df_val["label"] == get("other_class")] <- 0
  
  ## Training model model
  ## The return of the function is list with model
  print("Training model..")
  trained_model <-
    trainer_func(
      train_set      = df_train,
      validation_set = df_val,
      explanatory_variables = exp_vars ,
      target_variable = 'label',
      hypergrid = hypergrid
    )
  
  
  ## Saving other features with the model to use in test and serve
  print("Saving other features..")
  trained_model$exp_vars <- exp_vars
  trained_model$target_class <- target_class
  trained_model$other_class <- other_class
  trained_model$id_column <- id_column
  trained_model$variables_to_encode <- variables_to_encode
  trained_model$encodings <- encodings
  trained_model$best_params %>% as.data.frame() %>% print()
  print("Saving model..")
  trained_model %>% write_rds('/opt/ml_vol/model/artifacts/model.rds')
  print("Training done")
}

tryCatch(               
  
  # Specifying expression
  expr = {                     
    trainer(schema, data)
  },
  # Specifying error message
  error = function(e){      
    print("Train Error!")   
    write(e %>% as.character(),file="/opt/ml_vol/outputs/errors/train_failure.txt",append=FALSE)
  }
)

